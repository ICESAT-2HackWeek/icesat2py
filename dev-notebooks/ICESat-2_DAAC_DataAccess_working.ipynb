{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing ICESat-2 Data\n",
    "### Software Development Notebook\n",
    "This notebook outlines and begins development for functionality to ease ICESat-2 data access and download from the NASA NSIDC DAAC (NASA National Snow and Ice Data Center Distributed Active Archive Center). This space is meant to be transient and serve as a space for writing and testing code. Documentation and examples will be developed independently.\n",
    "\n",
    "#### Credits\n",
    "* contributers: Jessica Scheick\n",
    "* based initially on and modified from the 'NSIDC DAAC ICESat-2 Customize and Access.ipynb' tutorial by Amy Steiker\n",
    "* some code from the ICESat-2 Hackweek topolib project was also modified and used in the development of is2_data.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages, including icepyx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import getpass\n",
    "import socket\n",
    "import json\n",
    "import zipfile\n",
    "import io\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pprint\n",
    "import time\n",
    "#import geopandas as gpd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import fiona\n",
    "import h5py\n",
    "import re\n",
    "# To read KML files with geopandas, we will need to enable KML support in fiona (disabled by default)\n",
    "#fiona.drvsupport.supported_drivers['LIBKML'] = 'rw'\n",
    "#from shapely.geometry import Polygon, mapping\n",
    "#from shapely.geometry.polygon import orient\n",
    "from statistics import mean\n",
    "from requests.auth import HTTPBasicAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jessica/Scripts/github/icesat2py/icepyx\n"
     ]
    }
   ],
   "source": [
    "#change working directory\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from icepyx import is2class as ipd\n",
    "%autoreload 2\n",
    "#in order to use \"as ipd\", you have to use autoreload 2, which will automatically reload any module not excluded by being imported with %aimport -[module]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the icesat-2 data object class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a = ipd.Icesat2Data('ATL06',[-64, 66, -55, 72],['2019-02-22','2019-02-28'], \\\n",
    "                           start_time='00:00:00', end_time='23:59:59', version='2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATL06\n",
      "['2019-02-22', '2019-02-28']\n",
      "00:00:00\n",
      "23:59:59\n",
      "001\n",
      "['bounding box', [-64, 66, -55, 72]]\n"
     ]
    }
   ],
   "source": [
    "print(region_a.dataset)\n",
    "print(region_a.dates)\n",
    "print(region_a.start_time)\n",
    "print(region_a.end_time)\n",
    "print(region_a.dataset_version)\n",
    "print(region_a.spatial_extent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feed': {'updated': '2019-11-19T22:16:58.786Z', 'id': 'https://cmr.earthdata.nasa.gov:443/search/collections.json?short_name=ATL06', 'title': 'ECHO dataset metadata', 'entry': [{'processing_level_id': 'Level 3', 'boxes': ['-90 -180 90 180'], 'time_start': '2018-10-14T00:00:00.000Z', 'version_id': '001', 'dataset_id': 'ATLAS/ICESat-2 L3A Land Ice Height V001', 'has_spatial_subsetting': True, 'has_transforms': False, 'associations': {'services': ['S1568899363-NSIDC_ECS', 'S1613689509-NSIDC_ECS', 'S1613669681-NSIDC_ECS']}, 'has_variables': True, 'data_center': 'NSIDC_ECS', 'short_name': 'ATL06', 'organizations': ['NASA NSIDC DAAC', 'NASA/GSFC/EOS/ESDIS'], 'title': 'ATLAS/ICESat-2 L3A Land Ice Height V001', 'coordinate_system': 'CARTESIAN', 'summary': 'This data set (ATL06) provides geolocated, land-ice surface heights (above the WGS 84 ellipsoid, ITRF2014 reference frame), plus ancillary parameters that can be used to interpret and assess the quality of the height estimates. The data were acquired by the Advanced Topographic Laser Altimeter System (ATLAS) instrument on board the Ice, Cloud and land Elevation Satellite-2 (ICESat-2) observatory.', 'orbit_parameters': {'swath_width': '36.0', 'period': '94.29', 'inclination_angle': '92.0', 'number_of_orbits': '0.071428571', 'start_circular_latitude': '0.0'}, 'id': 'C1511847675-NSIDC_ECS', 'has_formats': True, 'original_format': 'ISO19115', 'archive_center': 'NASA NSIDC DAAC', 'has_temporal_subsetting': True, 'browse_flag': False, 'online_access_flag': True, 'links': [{'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://n5eil01u.ecs.nsidc.org/ATLAS/ATL06.001/'}, {'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1511847675-NSIDC_ECS&m=-87.87967837686685!9.890967019347585!1!1!0!0%2C2&tl=1542476530!4!!&q=atl06&ok=atl06'}, {'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://openaltimetry.org/'}, {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#', 'hreflang': 'en-US', 'href': 'https://doi.org/10.5067/ATLAS/ATL06.001'}, {'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#', 'hreflang': 'en-US', 'href': 'https://doi.org/10.5067/ATLAS/ATL06.001'}]}, {'processing_level_id': 'Level 3', 'boxes': ['-90 -180 90 180'], 'time_start': '2018-10-14T00:00:00.000Z', 'version_id': '002', 'dataset_id': 'ATLAS/ICESat-2 L3A Land Ice Height V002', 'has_spatial_subsetting': True, 'has_transforms': False, 'associations': {'services': ['S1568899363-NSIDC_ECS', 'S1613669681-NSIDC_ECS', 'S1613689509-NSIDC_ECS']}, 'has_variables': True, 'data_center': 'NSIDC_ECS', 'short_name': 'ATL06', 'organizations': ['NASA NSIDC DAAC', 'NASA/GSFC/EOS/ESDIS'], 'title': 'ATLAS/ICESat-2 L3A Land Ice Height V002', 'coordinate_system': 'CARTESIAN', 'summary': 'This data set (ATL06) provides geolocated, land-ice surface heights (above the WGS 84 ellipsoid, ITRF2014 reference frame), plus ancillary parameters that can be used to interpret and assess the quality of the height estimates. The data were acquired by the Advanced Topographic Laser Altimeter System (ATLAS) instrument on board the Ice, Cloud and land Elevation Satellite-2 (ICESat-2) observatory.', 'orbit_parameters': {'swath_width': '36.0', 'period': '94.29', 'inclination_angle': '92.0', 'number_of_orbits': '0.071428571', 'start_circular_latitude': '0.0'}, 'id': 'C1631076765-NSIDC_ECS', 'has_formats': True, 'original_format': 'ISO19115', 'archive_center': 'NASA NSIDC DAAC', 'has_temporal_subsetting': True, 'browse_flag': False, 'online_access_flag': True, 'links': [{'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://n5eil01u.ecs.nsidc.org/ATLAS/ATL06.002/'}, {'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://search.earthdata.nasa.gov/search/granules?p=C1631076765-NSIDC_ECS&q=atl06%20v002&m=-113.62703547966265!-24.431396484375!0!1!0!0%2C2&tl=1556125020!4'}, {'length': '0.0KB', 'rel': 'http://esipfed.org/ns/fedsearch/1.1/data#', 'hreflang': 'en-US', 'href': 'https://openaltimetry.org/'}, {'rel': 'http://esipfed.org/ns/fedsearch/1.1/metadata#', 'hreflang': 'en-US', 'href': 'https://doi.org/10.5067/ATLAS/ATL06.002'}, {'rel': 'http://esipfed.org/ns/fedsearch/1.1/documentation#', 'hreflang': 'en-US', 'href': 'https://doi.org/10.5067/ATLAS/ATL06.002'}]}]}}\n",
      "002\n"
     ]
    }
   ],
   "source": [
    "print(region_a.about_dataset())\n",
    "print(region_a.latest_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Earthdata Login password:  ········\n"
     ]
    }
   ],
   "source": [
    "session=region_a.earthdata_login('jessica.scheick','jessica.scheick@maine.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<requests.sessions.Session object at 0x11c661128>\n"
     ]
    }
   ],
   "source": [
    "print(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=session.get(capability_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseError",
     "evalue": "syntax error: line 1, column 0 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/jessica/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3267\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"<ipython-input-57-dc10a84b6ff5>\"\u001b[0m, line \u001b[1;32m1\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    root = ET.fromstring(response.content)\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/jessica/anaconda2/envs/icesat2-hackweek/lib/python3.6/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m1314\u001b[0;36m, in \u001b[0;35mXML\u001b[0;36m\u001b[0m\n\u001b[0;31m    parser.feed(text)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m syntax error: line 1, column 0\n"
     ]
    }
   ],
   "source": [
    "root = ET.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'ICESAT2', 'spatialSubsetting': 'true', 'spatialSubsettingShapefile': 'true', 'temporalSubsetting': 'true', 'type': 'both', 'maxGransSyncRequest': '100', 'maxGransAsyncRequest': '2000'}] ['/ancillary_data', '/ancillary_data/atlas_sdp_gps_epoch', '/ancillary_data/control', '/ancillary_data/data_end_utc', '/ancillary_data/data_start_utc', '/ancillary_data/end_cycle', '/ancillary_data/end_delta_time', '/ancillary_data/end_geoseg', '/ancillary_data/end_gpssow', '/ancillary_data/end_gpsweek', '/ancillary_data/end_orbit', '/ancillary_data/end_region', '/ancillary_data/end_rgt', '/ancillary_data/granule_end_utc', '/ancillary_data/granule_start_utc', '/ancillary_data/qa_at_interval', '/ancillary_data/release', '/ancillary_data/start_cycle', '/ancillary_data/start_delta_time', '/ancillary_data/start_geoseg', '/ancillary_data/start_gpssow', '/ancillary_data/start_gpsweek', '/ancillary_data/start_orbit', '/ancillary_data/start_region', '/ancillary_data/start_rgt', '/ancillary_data/version', '/ancillary_data/land_ice', '/ancillary_data/land_ice/dt_hist', '/ancillary_data/land_ice/fit_maxiter', '/ancillary_data/land_ice/fpb_maxiter', '/ancillary_data/land_ice/maxiter', '/ancillary_data/land_ice/max_res_ids', '/ancillary_data/land_ice/min_dist', '/ancillary_data/land_ice/min_gain_th', '/ancillary_data/land_ice/min_n_pe', '/ancillary_data/land_ice/min_n_sel', '/ancillary_data/land_ice/min_signal_conf', '/ancillary_data/land_ice/n_hist', '/ancillary_data/land_ice/nhist_bins', '/ancillary_data/land_ice/n_sigmas', '/ancillary_data/land_ice/proc_interval', '/ancillary_data/land_ice/rbin_width', '/ancillary_data/land_ice/sigma_beam', '/ancillary_data/land_ice/sigma_tx', '/ancillary_data/land_ice/t_dead', '/ancillary_data/land_ice/win_nsig', '/gt1l', '/gt1l/land_ice_segments', '/gt1l/land_ice_segments/atl06_quality_summary', '/gt1l/land_ice_segments/delta_time', '/gt1l/land_ice_segments/h_li', '/gt1l/land_ice_segments/h_li_sigma', '/gt1l/land_ice_segments/latitude', '/gt1l/land_ice_segments/longitude', '/gt1l/land_ice_segments/segment_id', '/gt1l/land_ice_segments/sigma_geo_h', '/gt1l/land_ice_segments/bias_correction', '/gt1l/land_ice_segments/bias_correction/fpb_mean_corr', '/gt1l/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt1l/land_ice_segments/bias_correction/fpb_med_corr', '/gt1l/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt1l/land_ice_segments/bias_correction/fpb_n_corr', '/gt1l/land_ice_segments/bias_correction/med_r_fit', '/gt1l/land_ice_segments/bias_correction/tx_mean_corr', '/gt1l/land_ice_segments/bias_correction/tx_med_corr', '/gt1l/land_ice_segments/dem', '/gt1l/land_ice_segments/dem/dem_flag', '/gt1l/land_ice_segments/dem/dem_h', '/gt1l/land_ice_segments/dem/geoid_h', '/gt1l/land_ice_segments/fit_statistics', '/gt1l/land_ice_segments/fit_statistics/dh_fit_dx', '/gt1l/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt1l/land_ice_segments/fit_statistics/dh_fit_dy', '/gt1l/land_ice_segments/fit_statistics/h_expected_rms', '/gt1l/land_ice_segments/fit_statistics/h_mean', '/gt1l/land_ice_segments/fit_statistics/h_rms_misfit', '/gt1l/land_ice_segments/fit_statistics/h_robust_sprd', '/gt1l/land_ice_segments/fit_statistics/n_fit_photons', '/gt1l/land_ice_segments/fit_statistics/n_seg_pulses', '/gt1l/land_ice_segments/fit_statistics/sigma_h_mean', '/gt1l/land_ice_segments/fit_statistics/signal_selection_source', '/gt1l/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt1l/land_ice_segments/fit_statistics/snr', '/gt1l/land_ice_segments/fit_statistics/snr_significance', '/gt1l/land_ice_segments/fit_statistics/w_surface_window_final', '/gt1l/land_ice_segments/geophysical', '/gt1l/land_ice_segments/geophysical/bckgrd', '/gt1l/land_ice_segments/geophysical/bsnow_conf', '/gt1l/land_ice_segments/geophysical/bsnow_h', '/gt1l/land_ice_segments/geophysical/bsnow_od', '/gt1l/land_ice_segments/geophysical/cloud_flg_asr', '/gt1l/land_ice_segments/geophysical/cloud_flg_atm', '/gt1l/land_ice_segments/geophysical/dac', '/gt1l/land_ice_segments/geophysical/e_bckgrd', '/gt1l/land_ice_segments/geophysical/msw_flag', '/gt1l/land_ice_segments/geophysical/neutat_delay_total', '/gt1l/land_ice_segments/geophysical/r_eff', '/gt1l/land_ice_segments/geophysical/solar_azimuth', '/gt1l/land_ice_segments/geophysical/solar_elevation', '/gt1l/land_ice_segments/geophysical/tide_earth', '/gt1l/land_ice_segments/geophysical/tide_equilibrium', '/gt1l/land_ice_segments/geophysical/tide_load', '/gt1l/land_ice_segments/geophysical/tide_ocean', '/gt1l/land_ice_segments/geophysical/tide_pole', '/gt1l/land_ice_segments/ground_track', '/gt1l/land_ice_segments/ground_track/ref_azimuth', '/gt1l/land_ice_segments/ground_track/ref_coelv', '/gt1l/land_ice_segments/ground_track/seg_azimuth', '/gt1l/land_ice_segments/ground_track/sigma_geo_at', '/gt1l/land_ice_segments/ground_track/sigma_geo_xt', '/gt1l/land_ice_segments/ground_track/x_atc', '/gt1l/land_ice_segments/ground_track/y_atc', '/gt1l/residual_histogram', '/gt1l/residual_histogram/bckgrd_per_bin', '/gt1l/residual_histogram/count', '/gt1l/residual_histogram/delta_time', '/gt1l/residual_histogram/dh', '/gt1l/residual_histogram/ds_segment_id', '/gt1l/residual_histogram/lat_mean', '/gt1l/residual_histogram/lon_mean', '/gt1l/residual_histogram/pulse_count', '/gt1l/residual_histogram/segment_id_list', '/gt1l/residual_histogram/x_atc_mean', '/gt1l/segment_quality', '/gt1l/segment_quality/delta_time', '/gt1l/segment_quality/record_number', '/gt1l/segment_quality/reference_pt_lat', '/gt1l/segment_quality/reference_pt_lon', '/gt1l/segment_quality/segment_id', '/gt1l/segment_quality/signal_selection_source', '/gt1l/segment_quality/signal_selection_status', '/gt1l/segment_quality/signal_selection_status/signal_selection_status_all', '/gt1l/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt1l/segment_quality/signal_selection_status/signal_selection_status_confident', '/gt1r', '/gt1r/land_ice_segments', '/gt1r/land_ice_segments/atl06_quality_summary', '/gt1r/land_ice_segments/delta_time', '/gt1r/land_ice_segments/h_li', '/gt1r/land_ice_segments/h_li_sigma', '/gt1r/land_ice_segments/latitude', '/gt1r/land_ice_segments/longitude', '/gt1r/land_ice_segments/segment_id', '/gt1r/land_ice_segments/sigma_geo_h', '/gt1r/land_ice_segments/bias_correction', '/gt1r/land_ice_segments/bias_correction/fpb_mean_corr', '/gt1r/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt1r/land_ice_segments/bias_correction/fpb_med_corr', '/gt1r/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt1r/land_ice_segments/bias_correction/fpb_n_corr', '/gt1r/land_ice_segments/bias_correction/med_r_fit', '/gt1r/land_ice_segments/bias_correction/tx_mean_corr', '/gt1r/land_ice_segments/bias_correction/tx_med_corr', '/gt1r/land_ice_segments/dem', '/gt1r/land_ice_segments/dem/dem_flag', '/gt1r/land_ice_segments/dem/dem_h', '/gt1r/land_ice_segments/dem/geoid_h', '/gt1r/land_ice_segments/fit_statistics', '/gt1r/land_ice_segments/fit_statistics/dh_fit_dx', '/gt1r/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt1r/land_ice_segments/fit_statistics/dh_fit_dy', '/gt1r/land_ice_segments/fit_statistics/h_expected_rms', '/gt1r/land_ice_segments/fit_statistics/h_mean', '/gt1r/land_ice_segments/fit_statistics/h_rms_misfit', '/gt1r/land_ice_segments/fit_statistics/h_robust_sprd', '/gt1r/land_ice_segments/fit_statistics/n_fit_photons', '/gt1r/land_ice_segments/fit_statistics/n_seg_pulses', '/gt1r/land_ice_segments/fit_statistics/sigma_h_mean', '/gt1r/land_ice_segments/fit_statistics/signal_selection_source', '/gt1r/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt1r/land_ice_segments/fit_statistics/snr', '/gt1r/land_ice_segments/fit_statistics/snr_significance', '/gt1r/land_ice_segments/fit_statistics/w_surface_window_final', '/gt1r/land_ice_segments/geophysical', '/gt1r/land_ice_segments/geophysical/bckgrd', '/gt1r/land_ice_segments/geophysical/bsnow_conf', '/gt1r/land_ice_segments/geophysical/bsnow_h', '/gt1r/land_ice_segments/geophysical/bsnow_od', '/gt1r/land_ice_segments/geophysical/cloud_flg_asr', '/gt1r/land_ice_segments/geophysical/cloud_flg_atm', '/gt1r/land_ice_segments/geophysical/dac', '/gt1r/land_ice_segments/geophysical/e_bckgrd', '/gt1r/land_ice_segments/geophysical/msw_flag', '/gt1r/land_ice_segments/geophysical/neutat_delay_total', '/gt1r/land_ice_segments/geophysical/r_eff', '/gt1r/land_ice_segments/geophysical/solar_azimuth', '/gt1r/land_ice_segments/geophysical/solar_elevation', '/gt1r/land_ice_segments/geophysical/tide_earth', '/gt1r/land_ice_segments/geophysical/tide_equilibrium', '/gt1r/land_ice_segments/geophysical/tide_load', '/gt1r/land_ice_segments/geophysical/tide_ocean', '/gt1r/land_ice_segments/geophysical/tide_pole', '/gt1r/land_ice_segments/ground_track', '/gt1r/land_ice_segments/ground_track/ref_azimuth', '/gt1r/land_ice_segments/ground_track/ref_coelv', '/gt1r/land_ice_segments/ground_track/seg_azimuth', '/gt1r/land_ice_segments/ground_track/sigma_geo_at', '/gt1r/land_ice_segments/ground_track/sigma_geo_xt', '/gt1r/land_ice_segments/ground_track/x_atc', '/gt1r/land_ice_segments/ground_track/y_atc', '/gt1r/residual_histogram', '/gt1r/residual_histogram/bckgrd_per_bin', '/gt1r/residual_histogram/count', '/gt1r/residual_histogram/delta_time', '/gt1r/residual_histogram/dh', '/gt1r/residual_histogram/ds_segment_id', '/gt1r/residual_histogram/lat_mean', '/gt1r/residual_histogram/lon_mean', '/gt1r/residual_histogram/pulse_count', '/gt1r/residual_histogram/segment_id_list', '/gt1r/residual_histogram/x_atc_mean', '/gt1r/segment_quality', '/gt1r/segment_quality/delta_time', '/gt1r/segment_quality/record_number', '/gt1r/segment_quality/reference_pt_lat', '/gt1r/segment_quality/reference_pt_lon', '/gt1r/segment_quality/segment_id', '/gt1r/segment_quality/signal_selection_source', '/gt1r/segment_quality/signal_selection_status', '/gt1r/segment_quality/signal_selection_status/signal_selection_status_all', '/gt1r/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt1r/segment_quality/signal_selection_status/signal_selection_status_confident', '/gt2l', '/gt2l/land_ice_segments', '/gt2l/land_ice_segments/atl06_quality_summary', '/gt2l/land_ice_segments/delta_time', '/gt2l/land_ice_segments/h_li', '/gt2l/land_ice_segments/h_li_sigma', '/gt2l/land_ice_segments/latitude', '/gt2l/land_ice_segments/longitude', '/gt2l/land_ice_segments/segment_id', '/gt2l/land_ice_segments/sigma_geo_h', '/gt2l/land_ice_segments/bias_correction', '/gt2l/land_ice_segments/bias_correction/fpb_mean_corr', '/gt2l/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt2l/land_ice_segments/bias_correction/fpb_med_corr', '/gt2l/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt2l/land_ice_segments/bias_correction/fpb_n_corr', '/gt2l/land_ice_segments/bias_correction/med_r_fit', '/gt2l/land_ice_segments/bias_correction/tx_mean_corr', '/gt2l/land_ice_segments/bias_correction/tx_med_corr', '/gt2l/land_ice_segments/dem', '/gt2l/land_ice_segments/dem/dem_flag', '/gt2l/land_ice_segments/dem/dem_h', '/gt2l/land_ice_segments/dem/geoid_h', '/gt2l/land_ice_segments/fit_statistics', '/gt2l/land_ice_segments/fit_statistics/dh_fit_dx', '/gt2l/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt2l/land_ice_segments/fit_statistics/dh_fit_dy', '/gt2l/land_ice_segments/fit_statistics/h_expected_rms', '/gt2l/land_ice_segments/fit_statistics/h_mean', '/gt2l/land_ice_segments/fit_statistics/h_rms_misfit', '/gt2l/land_ice_segments/fit_statistics/h_robust_sprd', '/gt2l/land_ice_segments/fit_statistics/n_fit_photons', '/gt2l/land_ice_segments/fit_statistics/n_seg_pulses', '/gt2l/land_ice_segments/fit_statistics/sigma_h_mean', '/gt2l/land_ice_segments/fit_statistics/signal_selection_source', '/gt2l/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt2l/land_ice_segments/fit_statistics/snr', '/gt2l/land_ice_segments/fit_statistics/snr_significance', '/gt2l/land_ice_segments/fit_statistics/w_surface_window_final', '/gt2l/land_ice_segments/geophysical', '/gt2l/land_ice_segments/geophysical/bckgrd', '/gt2l/land_ice_segments/geophysical/bsnow_conf', '/gt2l/land_ice_segments/geophysical/bsnow_h', '/gt2l/land_ice_segments/geophysical/bsnow_od', '/gt2l/land_ice_segments/geophysical/cloud_flg_asr', '/gt2l/land_ice_segments/geophysical/cloud_flg_atm', '/gt2l/land_ice_segments/geophysical/dac', '/gt2l/land_ice_segments/geophysical/e_bckgrd', '/gt2l/land_ice_segments/geophysical/msw_flag', '/gt2l/land_ice_segments/geophysical/neutat_delay_total', '/gt2l/land_ice_segments/geophysical/r_eff', '/gt2l/land_ice_segments/geophysical/solar_azimuth', '/gt2l/land_ice_segments/geophysical/solar_elevation', '/gt2l/land_ice_segments/geophysical/tide_earth', '/gt2l/land_ice_segments/geophysical/tide_equilibrium', '/gt2l/land_ice_segments/geophysical/tide_load', '/gt2l/land_ice_segments/geophysical/tide_ocean', '/gt2l/land_ice_segments/geophysical/tide_pole', '/gt2l/land_ice_segments/ground_track', '/gt2l/land_ice_segments/ground_track/ref_azimuth', '/gt2l/land_ice_segments/ground_track/ref_coelv', '/gt2l/land_ice_segments/ground_track/seg_azimuth', '/gt2l/land_ice_segments/ground_track/sigma_geo_at', '/gt2l/land_ice_segments/ground_track/sigma_geo_xt', '/gt2l/land_ice_segments/ground_track/x_atc', '/gt2l/land_ice_segments/ground_track/y_atc', '/gt2l/residual_histogram', '/gt2l/residual_histogram/bckgrd_per_bin', '/gt2l/residual_histogram/count', '/gt2l/residual_histogram/delta_time', '/gt2l/residual_histogram/dh', '/gt2l/residual_histogram/ds_segment_id', '/gt2l/residual_histogram/lat_mean', '/gt2l/residual_histogram/lon_mean', '/gt2l/residual_histogram/pulse_count', '/gt2l/residual_histogram/segment_id_list', '/gt2l/residual_histogram/x_atc_mean', '/gt2l/segment_quality', '/gt2l/segment_quality/delta_time', '/gt2l/segment_quality/record_number', '/gt2l/segment_quality/reference_pt_lat', '/gt2l/segment_quality/reference_pt_lon', '/gt2l/segment_quality/segment_id', '/gt2l/segment_quality/signal_selection_source', '/gt2l/segment_quality/signal_selection_status', '/gt2l/segment_quality/signal_selection_status/signal_selection_status_all', '/gt2l/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt2l/segment_quality/signal_selection_status/signal_selection_status_confident', '/gt2r', '/gt2r/land_ice_segments', '/gt2r/land_ice_segments/atl06_quality_summary', '/gt2r/land_ice_segments/delta_time', '/gt2r/land_ice_segments/h_li', '/gt2r/land_ice_segments/h_li_sigma', '/gt2r/land_ice_segments/latitude', '/gt2r/land_ice_segments/longitude', '/gt2r/land_ice_segments/segment_id', '/gt2r/land_ice_segments/sigma_geo_h', '/gt2r/land_ice_segments/bias_correction', '/gt2r/land_ice_segments/bias_correction/fpb_mean_corr', '/gt2r/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt2r/land_ice_segments/bias_correction/fpb_med_corr', '/gt2r/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt2r/land_ice_segments/bias_correction/fpb_n_corr', '/gt2r/land_ice_segments/bias_correction/med_r_fit', '/gt2r/land_ice_segments/bias_correction/tx_mean_corr', '/gt2r/land_ice_segments/bias_correction/tx_med_corr', '/gt2r/land_ice_segments/dem', '/gt2r/land_ice_segments/dem/dem_flag', '/gt2r/land_ice_segments/dem/dem_h', '/gt2r/land_ice_segments/dem/geoid_h', '/gt2r/land_ice_segments/fit_statistics', '/gt2r/land_ice_segments/fit_statistics/dh_fit_dx', '/gt2r/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt2r/land_ice_segments/fit_statistics/dh_fit_dy', '/gt2r/land_ice_segments/fit_statistics/h_expected_rms', '/gt2r/land_ice_segments/fit_statistics/h_mean', '/gt2r/land_ice_segments/fit_statistics/h_rms_misfit', '/gt2r/land_ice_segments/fit_statistics/h_robust_sprd', '/gt2r/land_ice_segments/fit_statistics/n_fit_photons', '/gt2r/land_ice_segments/fit_statistics/n_seg_pulses', '/gt2r/land_ice_segments/fit_statistics/sigma_h_mean', '/gt2r/land_ice_segments/fit_statistics/signal_selection_source', '/gt2r/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt2r/land_ice_segments/fit_statistics/snr', '/gt2r/land_ice_segments/fit_statistics/snr_significance', '/gt2r/land_ice_segments/fit_statistics/w_surface_window_final', '/gt2r/land_ice_segments/geophysical', '/gt2r/land_ice_segments/geophysical/bckgrd', '/gt2r/land_ice_segments/geophysical/bsnow_conf', '/gt2r/land_ice_segments/geophysical/bsnow_h', '/gt2r/land_ice_segments/geophysical/bsnow_od', '/gt2r/land_ice_segments/geophysical/cloud_flg_asr', '/gt2r/land_ice_segments/geophysical/cloud_flg_atm', '/gt2r/land_ice_segments/geophysical/dac', '/gt2r/land_ice_segments/geophysical/e_bckgrd', '/gt2r/land_ice_segments/geophysical/msw_flag', '/gt2r/land_ice_segments/geophysical/neutat_delay_total', '/gt2r/land_ice_segments/geophysical/r_eff', '/gt2r/land_ice_segments/geophysical/solar_azimuth', '/gt2r/land_ice_segments/geophysical/solar_elevation', '/gt2r/land_ice_segments/geophysical/tide_earth', '/gt2r/land_ice_segments/geophysical/tide_equilibrium', '/gt2r/land_ice_segments/geophysical/tide_load', '/gt2r/land_ice_segments/geophysical/tide_ocean', '/gt2r/land_ice_segments/geophysical/tide_pole', '/gt2r/land_ice_segments/ground_track', '/gt2r/land_ice_segments/ground_track/ref_azimuth', '/gt2r/land_ice_segments/ground_track/ref_coelv', '/gt2r/land_ice_segments/ground_track/seg_azimuth', '/gt2r/land_ice_segments/ground_track/sigma_geo_at', '/gt2r/land_ice_segments/ground_track/sigma_geo_xt', '/gt2r/land_ice_segments/ground_track/x_atc', '/gt2r/land_ice_segments/ground_track/y_atc', '/gt2r/residual_histogram', '/gt2r/residual_histogram/bckgrd_per_bin', '/gt2r/residual_histogram/count', '/gt2r/residual_histogram/delta_time', '/gt2r/residual_histogram/dh', '/gt2r/residual_histogram/ds_segment_id', '/gt2r/residual_histogram/lat_mean', '/gt2r/residual_histogram/lon_mean', '/gt2r/residual_histogram/pulse_count', '/gt2r/residual_histogram/segment_id_list', '/gt2r/residual_histogram/x_atc_mean', '/gt2r/segment_quality', '/gt2r/segment_quality/delta_time', '/gt2r/segment_quality/record_number', '/gt2r/segment_quality/reference_pt_lat', '/gt2r/segment_quality/reference_pt_lon', '/gt2r/segment_quality/segment_id', '/gt2r/segment_quality/signal_selection_source', '/gt2r/segment_quality/signal_selection_status', '/gt2r/segment_quality/signal_selection_status/signal_selection_status_all', '/gt2r/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt2r/segment_quality/signal_selection_status/signal_selection_status_confident', '/gt3l', '/gt3l/land_ice_segments', '/gt3l/land_ice_segments/atl06_quality_summary', '/gt3l/land_ice_segments/delta_time', '/gt3l/land_ice_segments/h_li', '/gt3l/land_ice_segments/h_li_sigma', '/gt3l/land_ice_segments/latitude', '/gt3l/land_ice_segments/longitude', '/gt3l/land_ice_segments/segment_id', '/gt3l/land_ice_segments/sigma_geo_h', '/gt3l/land_ice_segments/bias_correction', '/gt3l/land_ice_segments/bias_correction/fpb_mean_corr', '/gt3l/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt3l/land_ice_segments/bias_correction/fpb_med_corr', '/gt3l/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt3l/land_ice_segments/bias_correction/fpb_n_corr', '/gt3l/land_ice_segments/bias_correction/med_r_fit', '/gt3l/land_ice_segments/bias_correction/tx_mean_corr', '/gt3l/land_ice_segments/bias_correction/tx_med_corr', '/gt3l/land_ice_segments/dem', '/gt3l/land_ice_segments/dem/dem_flag', '/gt3l/land_ice_segments/dem/dem_h', '/gt3l/land_ice_segments/dem/geoid_h', '/gt3l/land_ice_segments/fit_statistics', '/gt3l/land_ice_segments/fit_statistics/dh_fit_dx', '/gt3l/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt3l/land_ice_segments/fit_statistics/dh_fit_dy', '/gt3l/land_ice_segments/fit_statistics/h_expected_rms', '/gt3l/land_ice_segments/fit_statistics/h_mean', '/gt3l/land_ice_segments/fit_statistics/h_rms_misfit', '/gt3l/land_ice_segments/fit_statistics/h_robust_sprd', '/gt3l/land_ice_segments/fit_statistics/n_fit_photons', '/gt3l/land_ice_segments/fit_statistics/n_seg_pulses', '/gt3l/land_ice_segments/fit_statistics/sigma_h_mean', '/gt3l/land_ice_segments/fit_statistics/signal_selection_source', '/gt3l/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt3l/land_ice_segments/fit_statistics/snr', '/gt3l/land_ice_segments/fit_statistics/snr_significance', '/gt3l/land_ice_segments/fit_statistics/w_surface_window_final', '/gt3l/land_ice_segments/geophysical', '/gt3l/land_ice_segments/geophysical/bckgrd', '/gt3l/land_ice_segments/geophysical/bsnow_conf', '/gt3l/land_ice_segments/geophysical/bsnow_h', '/gt3l/land_ice_segments/geophysical/bsnow_od', '/gt3l/land_ice_segments/geophysical/cloud_flg_asr', '/gt3l/land_ice_segments/geophysical/cloud_flg_atm', '/gt3l/land_ice_segments/geophysical/dac', '/gt3l/land_ice_segments/geophysical/e_bckgrd', '/gt3l/land_ice_segments/geophysical/msw_flag', '/gt3l/land_ice_segments/geophysical/neutat_delay_total', '/gt3l/land_ice_segments/geophysical/r_eff', '/gt3l/land_ice_segments/geophysical/solar_azimuth', '/gt3l/land_ice_segments/geophysical/solar_elevation', '/gt3l/land_ice_segments/geophysical/tide_earth', '/gt3l/land_ice_segments/geophysical/tide_equilibrium', '/gt3l/land_ice_segments/geophysical/tide_load', '/gt3l/land_ice_segments/geophysical/tide_ocean', '/gt3l/land_ice_segments/geophysical/tide_pole', '/gt3l/land_ice_segments/ground_track', '/gt3l/land_ice_segments/ground_track/ref_azimuth', '/gt3l/land_ice_segments/ground_track/ref_coelv', '/gt3l/land_ice_segments/ground_track/seg_azimuth', '/gt3l/land_ice_segments/ground_track/sigma_geo_at', '/gt3l/land_ice_segments/ground_track/sigma_geo_xt', '/gt3l/land_ice_segments/ground_track/x_atc', '/gt3l/land_ice_segments/ground_track/y_atc', '/gt3l/residual_histogram', '/gt3l/residual_histogram/bckgrd_per_bin', '/gt3l/residual_histogram/count', '/gt3l/residual_histogram/delta_time', '/gt3l/residual_histogram/dh', '/gt3l/residual_histogram/ds_segment_id', '/gt3l/residual_histogram/lat_mean', '/gt3l/residual_histogram/lon_mean', '/gt3l/residual_histogram/pulse_count', '/gt3l/residual_histogram/segment_id_list', '/gt3l/residual_histogram/x_atc_mean', '/gt3l/segment_quality', '/gt3l/segment_quality/delta_time', '/gt3l/segment_quality/record_number', '/gt3l/segment_quality/reference_pt_lat', '/gt3l/segment_quality/reference_pt_lon', '/gt3l/segment_quality/segment_id', '/gt3l/segment_quality/signal_selection_source', '/gt3l/segment_quality/signal_selection_status', '/gt3l/segment_quality/signal_selection_status/signal_selection_status_all', '/gt3l/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt3l/segment_quality/signal_selection_status/signal_selection_status_confident', '/gt3r', '/gt3r/land_ice_segments', '/gt3r/land_ice_segments/atl06_quality_summary', '/gt3r/land_ice_segments/delta_time', '/gt3r/land_ice_segments/h_li', '/gt3r/land_ice_segments/h_li_sigma', '/gt3r/land_ice_segments/latitude', '/gt3r/land_ice_segments/longitude', '/gt3r/land_ice_segments/segment_id', '/gt3r/land_ice_segments/sigma_geo_h', '/gt3r/land_ice_segments/bias_correction', '/gt3r/land_ice_segments/bias_correction/fpb_mean_corr', '/gt3r/land_ice_segments/bias_correction/fpb_mean_corr_sigma', '/gt3r/land_ice_segments/bias_correction/fpb_med_corr', '/gt3r/land_ice_segments/bias_correction/fpb_med_corr_sigma', '/gt3r/land_ice_segments/bias_correction/fpb_n_corr', '/gt3r/land_ice_segments/bias_correction/med_r_fit', '/gt3r/land_ice_segments/bias_correction/tx_mean_corr', '/gt3r/land_ice_segments/bias_correction/tx_med_corr', '/gt3r/land_ice_segments/dem', '/gt3r/land_ice_segments/dem/dem_flag', '/gt3r/land_ice_segments/dem/dem_h', '/gt3r/land_ice_segments/dem/geoid_h', '/gt3r/land_ice_segments/fit_statistics', '/gt3r/land_ice_segments/fit_statistics/dh_fit_dx', '/gt3r/land_ice_segments/fit_statistics/dh_fit_dx_sigma', '/gt3r/land_ice_segments/fit_statistics/dh_fit_dy', '/gt3r/land_ice_segments/fit_statistics/h_expected_rms', '/gt3r/land_ice_segments/fit_statistics/h_mean', '/gt3r/land_ice_segments/fit_statistics/h_rms_misfit', '/gt3r/land_ice_segments/fit_statistics/h_robust_sprd', '/gt3r/land_ice_segments/fit_statistics/n_fit_photons', '/gt3r/land_ice_segments/fit_statistics/n_seg_pulses', '/gt3r/land_ice_segments/fit_statistics/sigma_h_mean', '/gt3r/land_ice_segments/fit_statistics/signal_selection_source', '/gt3r/land_ice_segments/fit_statistics/signal_selection_source_status', '/gt3r/land_ice_segments/fit_statistics/snr', '/gt3r/land_ice_segments/fit_statistics/snr_significance', '/gt3r/land_ice_segments/fit_statistics/w_surface_window_final', '/gt3r/land_ice_segments/geophysical', '/gt3r/land_ice_segments/geophysical/bckgrd', '/gt3r/land_ice_segments/geophysical/bsnow_conf', '/gt3r/land_ice_segments/geophysical/bsnow_h', '/gt3r/land_ice_segments/geophysical/bsnow_od', '/gt3r/land_ice_segments/geophysical/cloud_flg_asr', '/gt3r/land_ice_segments/geophysical/cloud_flg_atm', '/gt3r/land_ice_segments/geophysical/dac', '/gt3r/land_ice_segments/geophysical/e_bckgrd', '/gt3r/land_ice_segments/geophysical/msw_flag', '/gt3r/land_ice_segments/geophysical/neutat_delay_total', '/gt3r/land_ice_segments/geophysical/r_eff', '/gt3r/land_ice_segments/geophysical/solar_azimuth', '/gt3r/land_ice_segments/geophysical/solar_elevation', '/gt3r/land_ice_segments/geophysical/tide_earth', '/gt3r/land_ice_segments/geophysical/tide_equilibrium', '/gt3r/land_ice_segments/geophysical/tide_load', '/gt3r/land_ice_segments/geophysical/tide_ocean', '/gt3r/land_ice_segments/geophysical/tide_pole', '/gt3r/land_ice_segments/ground_track', '/gt3r/land_ice_segments/ground_track/ref_azimuth', '/gt3r/land_ice_segments/ground_track/ref_coelv', '/gt3r/land_ice_segments/ground_track/seg_azimuth', '/gt3r/land_ice_segments/ground_track/sigma_geo_at', '/gt3r/land_ice_segments/ground_track/sigma_geo_xt', '/gt3r/land_ice_segments/ground_track/x_atc', '/gt3r/land_ice_segments/ground_track/y_atc', '/gt3r/residual_histogram', '/gt3r/residual_histogram/bckgrd_per_bin', '/gt3r/residual_histogram/count', '/gt3r/residual_histogram/delta_time', '/gt3r/residual_histogram/dh', '/gt3r/residual_histogram/ds_segment_id', '/gt3r/residual_histogram/lat_mean', '/gt3r/residual_histogram/lon_mean', '/gt3r/residual_histogram/pulse_count', '/gt3r/residual_histogram/segment_id_list', '/gt3r/residual_histogram/x_atc_mean', '/gt3r/segment_quality', '/gt3r/segment_quality/delta_time', '/gt3r/segment_quality/record_number', '/gt3r/segment_quality/reference_pt_lat', '/gt3r/segment_quality/reference_pt_lon', '/gt3r/segment_quality/segment_id', '/gt3r/segment_quality/signal_selection_source', '/gt3r/segment_quality/signal_selection_status', '/gt3r/segment_quality/signal_selection_status/signal_selection_status_all', '/gt3r/segment_quality/signal_selection_status/signal_selection_status_backup', '/gt3r/segment_quality/signal_selection_status/signal_selection_status_confident', '/orbit_info', '/orbit_info/crossing_time', '/orbit_info/cycle_number', '/orbit_info/lan', '/orbit_info/orbit_number', '/orbit_info/rgt', '/orbit_info/sc_orient', '/orbit_info/sc_orient_time', '/quality_assessment', '/quality_assessment/qa_granule_fail_reason', '/quality_assessment/qa_granule_pass_fail', '/quality_assessment/gt1l', '/quality_assessment/gt1l/delta_time', '/quality_assessment/gt1l/lat_mean', '/quality_assessment/gt1l/lon_mean', '/quality_assessment/gt1l/signal_selection_source_fraction_0', '/quality_assessment/gt1l/signal_selection_source_fraction_1', '/quality_assessment/gt1l/signal_selection_source_fraction_2', '/quality_assessment/gt1l/signal_selection_source_fraction_3', '/quality_assessment/gt1r', '/quality_assessment/gt1r/delta_time', '/quality_assessment/gt1r/lat_mean', '/quality_assessment/gt1r/lon_mean', '/quality_assessment/gt1r/signal_selection_source_fraction_0', '/quality_assessment/gt1r/signal_selection_source_fraction_1', '/quality_assessment/gt1r/signal_selection_source_fraction_2', '/quality_assessment/gt1r/signal_selection_source_fraction_3', '/quality_assessment/gt2l', '/quality_assessment/gt2l/delta_time', '/quality_assessment/gt2l/lat_mean', '/quality_assessment/gt2l/lon_mean', '/quality_assessment/gt2l/signal_selection_source_fraction_0', '/quality_assessment/gt2l/signal_selection_source_fraction_1', '/quality_assessment/gt2l/signal_selection_source_fraction_2', '/quality_assessment/gt2l/signal_selection_source_fraction_3', '/quality_assessment/gt2r', '/quality_assessment/gt2r/delta_time', '/quality_assessment/gt2r/lat_mean', '/quality_assessment/gt2r/lon_mean', '/quality_assessment/gt2r/signal_selection_source_fraction_0', '/quality_assessment/gt2r/signal_selection_source_fraction_1', '/quality_assessment/gt2r/signal_selection_source_fraction_2', '/quality_assessment/gt2r/signal_selection_source_fraction_3', '/quality_assessment/gt3l', '/quality_assessment/gt3l/delta_time', '/quality_assessment/gt3l/lat_mean', '/quality_assessment/gt3l/lon_mean', '/quality_assessment/gt3l/signal_selection_source_fraction_0', '/quality_assessment/gt3l/signal_selection_source_fraction_1', '/quality_assessment/gt3l/signal_selection_source_fraction_2', '/quality_assessment/gt3l/signal_selection_source_fraction_3', '/quality_assessment/gt3r', '/quality_assessment/gt3r/delta_time', '/quality_assessment/gt3r/lat_mean', '/quality_assessment/gt3r/lon_mean', '/quality_assessment/gt3r/signal_selection_source_fraction_0', '/quality_assessment/gt3r/signal_selection_source_fraction_1', '/quality_assessment/gt3r/signal_selection_source_fraction_2', '/quality_assessment/gt3r/signal_selection_source_fraction_3'] ['TABULAR_ASCII', 'NetCDF4-CF', 'Shapefile', 'NetCDF-3'] [',TABULAR_ASCII,NetCDF4-CF,Shapefile,NetCDF-3'] [] []\n"
     ]
    }
   ],
   "source": [
    "region_a.get_custom_options(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Earthdata Login password:  ········\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='n5eil02u.ecs.nsidc.org', port=443): Max retries exceeded with url: /egi/capabilities/ATL06.002.xml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1163ca4e0>: Failed to establish a new connection: [Errno 61] Connection refused',))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 159\u001b[0;31m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[0;32m--> 168\u001b[0;31m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x1163ca4e0>: Failed to establish a new connection: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[0;32m--> 638\u001b[0;31m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[1;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='n5eil02u.ecs.nsidc.org', port=443): Max retries exceeded with url: /egi/capabilities/ATL06.002.xml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1163ca4e0>: Failed to establish a new connection: [Errno 61] Connection refused',))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e57840ebee8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearthdata_login\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jessica.scheick'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'jessica.scheick@maine.edu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Scripts/github/icepyx/working-forks/icesat2py/icesat2py/is2_data.py\u001b[0m in \u001b[0;36mearthdata_login\u001b[0;34m(self, uid, email)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcapability_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'https://n5eil02u.ecs.nsidc.org/egi/capabilities/{self.dataset}.{self.version}.xml'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapability_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpswd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    514\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='n5eil02u.ecs.nsidc.org', port=443): Max retries exceeded with url: /egi/capabilities/ATL06.002.xml (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x1163ca4e0>: Failed to establish a new connection: [Errno 61] Connection refused',))"
     ]
    }
   ],
   "source": [
    "session=region_a.earthdata_login('jessica.scheick','jessica.scheick@maine.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<icesat2py.is2_data.Icesat2Data at 0x11909a128>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temporal': '2019-02-22T00:00:00Z,2019-02-28T23:59:59Z'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Icesat2Data.cmr_fmt_temporal(region_a.start, region_a.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bbox': '-64,66,-55,72'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipd.Icesat2Data.cmr_fmt_spatial(region_a.extent_type, region_a.spatial_extent[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a.build_CMR_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'short_name': 'ATL06',\n",
       " 'version': '002',\n",
       " 'temporal': '2019-02-22T12:30:30Z, 2019-02-28T10:20:20Z',\n",
       " 'bounding_box': '-64,66,-55,72'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a.CMRparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a.build_reqconfig_params('download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'email': 'jessica.scheick@maine.edu',\n",
       " 'token': 'EEE2C680-46F6-EBF6-B4FF-DB181469D055',\n",
       " 'page_size': 10,\n",
       " 'page_num': 2,\n",
       " 'request_mode': 'async',\n",
       " 'agent': 'NO',\n",
       " 'include_meta': 'Y'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a.reqparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_a.build_subset_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': '2019-02-22T00:00:00,2019-02-28T23:59:59', 'bbox': '-64,66,-55,72'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a.subsetparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number of available granules': 7,\n",
       " 'Average size of granules (MB)': 35.445385387971434,\n",
       " 'Total size of all granules (MB)': 248.11769771580003}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a.avail_granules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Icesat2Data' object has no attribute 'granules'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-e55539790b9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregion_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgranules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Icesat2Data' object has no attribute 'granules'"
     ]
    }
   ],
   "source": [
    "region_a.granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order ID:  5000000421344\n",
      "Data request  1  is submitting...\n",
      "Initial request status is  processing\n",
      "Status is not complete. Trying again.\n",
      "Retry request status is:  processing\n",
      "Status is not complete. Trying again.\n",
      "Retry request status is:  complete_with_errors\n",
      "error messages:\n",
      "['166290953:NoMatchingData - No data found that matched subset constraints. '\n",
      " 'Exit code 3.',\n",
      " '166232766:NoMatchingData - No data found that matched subset constraints. '\n",
      " 'Exit code 3.',\n",
      " '166242951:NoMatchingData - No data found that matched subset constraints. '\n",
      " 'Exit code 3.',\n",
      " 'PT12.177S',\n",
      " 'ICESAT2']\n"
     ]
    }
   ],
   "source": [
    "region_a.order_granules(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order ID:  5000000421328\n",
      "Data request  1  is submitting...\n",
      "Initial request status is  processing\n",
      "Status is not complete. Trying again.\n",
      "Retry request status is:  complete\n"
     ]
    }
   ],
   "source": [
    "region_a.order_granules(session, subset=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order:  1\n",
      "Request HTTP response:  201\n",
      "Order request URL:  https://n5eil02u.ecs.nsidc.org/egi/request?short_name=ATL06&version=002&temporal=2019-02-22T00%3A00%3A00Z%2C2019-02-28T23%3A59%3A59Z&bounding_box=-64%2C66%2C-55%2C72&page_size=10&page_num=1&request_mode=async&agent=NO&include_meta=Y\n",
      "Order request response XML content:  b'<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n<eesi:agentResponse xsi:schemaLocation=\"http://eosdis.nasa.gov/esi/rsp/e https://newsroom.gsfc.nasa.gov/esi/8.1/schemas/ESIAgentResponseExternal.xsd\" xmlns=\"\" xmlns:iesi=\"http://eosdis.nasa.gov/esi/rsp/i\" xmlns:ssw=\"http://newsroom.gsfc.nasa.gov/esi/rsp/ssw\" xmlns:eesi=\"http://eosdis.nasa.gov/esi/rsp/e\" xmlns:esi=\"http://eosdis.nasa.gov/esi/rsp\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\\n    <order>\\n        <orderId>5000000420015</orderId>\\n        <Instructions>You may receive an email about your order if you specified an EMAIL address. &lt;br/&gt;&lt;br/&gt;The instructions used to process this order are:  Processing tool=NO. Include metadata and processing history=Y. Granule id(s)=SC:ATL06.002:166252035,SC:ATL06.002:166228209,SC:ATL06.002:166290953,SC:ATL06.002:166227755,SC:ATL06.002:166266202,SC:ATL06.002:166232766,SC:ATL06.002:166242951.</Instructions>\\n    </order>\\n    <contactInformation>\\n        <contactName>NSIDC User Services</contactName>\\n        <contactEmail>nsidc@nsidc.org</contactEmail>\\n    </contactInformation>\\n    <processInfo>\\n        <processDuration>PT0.145S</processDuration>\\n        <subagentId>NO</subagentId>\\n    </processInfo>\\n    <requestStatus>\\n        <status>processing</status>\\n        <numberProcessed>0</numberProcessed>\\n        <totalNumber>7</totalNumber>\\n    </requestStatus>\\n</eesi:agentResponse>\\n'\n",
      "<Element 'orderId' at 0x114d07638>\n",
      "<Element 'Instructions' at 0x114d07278>\n",
      "order ID:  5000000420015\n",
      "status URL:  https://n5eil02u.ecs.nsidc.org/egi/request/5000000420015\n",
      "HTTP response from order response URL:  201\n",
      "Data request  1  is submitting...\n",
      "Initial request status is  processing\n",
      "Status is not complete. Trying again.\n",
      "Retry request status is:  complete\n"
     ]
    }
   ],
   "source": [
    "region_a.order_granules(session, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5000000421328']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_a.orderIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order ID:  5000000420008\n",
      "Data request  1  is submitting...\n",
      "Initial request status is  processing\n",
      "Status is not complete. Trying again.\n",
      "Retry request status is:  complete\n",
      "Beginning download of zipped output...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-ff675248664b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregion_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_granules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/Users/jessica/Scripts/github/icesat2py/icepyx/download/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Scripts/github/icesat2py/icepyx/icepyx/core/is2class.py\u001b[0m in \u001b[0;36mdownload_granules\u001b[0;34m(self, session, path, verbose)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Zip download URL: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownloadURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Beginning download of zipped output...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m             \u001b[0mzip_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloadURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0;31m# Raise bad request: Loop will stop for bad response code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0mzip_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mcontent\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONTENT_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content_consumed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \"\"\"\n\u001b[1;32m    489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupports_chunked_reads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread_chunked\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m                 decoded = self._decode(chunk, decode_content=decode_content,\n\u001b[1;32m    671\u001b[0m                                        flush_decoder=False)\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_handle_chunk\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# amt > self.chunk_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 624\u001b[0;31m             \u001b[0mreturned_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Toss the CRLF at the end of the chunk.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXAMOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Unexpected EOF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/icesat2-hackweek/lib/python3.6/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "region_a.download_granules(session,'/Users/jessica/Scripts/github/icesat2py/icepyx/download/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order:  1\n",
      "Request HTTP response:  201\n",
      "Order request URL:  https://n5eil02u.ecs.nsidc.org/egi/request?short_name=ATL06&version=002&temporal=2019-02-22T00%3A00%3A00Z%2C2019-02-28T23%3A59%3A59Z&bounding_box=-64%2C66%2C-55%2C72&page_size=10&page_num=1&request_mode=async&agent=NO&include_meta=Y\n",
      "Order request response XML content:  b'<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?>\\n<eesi:agentResponse xsi:schemaLocation=\"http://eosdis.nasa.gov/esi/rsp/e https://newsroom.gsfc.nasa.gov/esi/8.1/schemas/ESIAgentResponseExternal.xsd\" xmlns=\"\" xmlns:iesi=\"http://eosdis.nasa.gov/esi/rsp/i\" xmlns:ssw=\"http://newsroom.gsfc.nasa.gov/esi/rsp/ssw\" xmlns:eesi=\"http://eosdis.nasa.gov/esi/rsp/e\" xmlns:esi=\"http://eosdis.nasa.gov/esi/rsp\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\">\\n    <order>\\n        <orderId>5000000420018</orderId>\\n        <Instructions>You may receive an email about your order if you specified an EMAIL address. &lt;br/&gt;&lt;br/&gt;The instructions used to process this order are:  Processing tool=NO. Include metadata and processing history=Y. Granule id(s)=SC:ATL06.002:166252035,SC:ATL06.002:166228209,SC:ATL06.002:166290953,SC:ATL06.002:166227755,SC:ATL06.002:166266202,SC:ATL06.002:166232766,SC:ATL06.002:166242951.</Instructions>\\n    </order>\\n    <contactInformation>\\n        <contactName>NSIDC User Services</contactName>\\n        <contactEmail>nsidc@nsidc.org</contactEmail>\\n    </contactInformation>\\n    <processInfo>\\n        <processDuration>PT0.110S</processDuration>\\n        <subagentId>NO</subagentId>\\n    </processInfo>\\n    <requestStatus>\\n        <status>processing</status>\\n        <numberProcessed>0</numberProcessed>\\n        <totalNumber>7</totalNumber>\\n    </requestStatus>\\n</eesi:agentResponse>\\n'\n",
      "<Element 'orderId' at 0x114d079a8>\n",
      "<Element 'Instructions' at 0x114d07e08>\n",
      "order ID:  5000000420018\n",
      "status URL:  https://n5eil02u.ecs.nsidc.org/egi/request/5000000420018\n",
      "HTTP response from order response URL:  201\n",
      "Data request  1  is submitting...\n",
      "Initial request status is  processing\n",
      "Status is not complete. Trying again.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please confirm that you have submitted a valid order and it has successfully completed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Scripts/github/icesat2py/icepyx/icepyx/core/is2class.py\u001b[0m in \u001b[0;36mdownload_granules\u001b[0;34m(self, session, path, verbose)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_granules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Scripts/github/icesat2py/icepyx/icepyx/core/is2class.py\u001b[0m in \u001b[0;36morder_granules\u001b[0;34m(self, session, verbose)\u001b[0m\n\u001b[1;32m    592\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Status is not complete. Trying again.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m                 \u001b[0mloop_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatusURL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-3107cf157bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregion_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_granules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/Users/jessica/Scripts/github/icesat2py/icepyx/download/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Scripts/github/icesat2py/icepyx/icepyx/core/is2class.py\u001b[0m in \u001b[0;36mdownload_granules\u001b[0;34m(self, session, path, verbose)\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'orderIDs'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morderIDs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Please confirm that you have submitted a valid order and it has successfully completed.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please confirm that you have submitted a valid order and it has successfully completed."
     ]
    }
   ],
   "source": [
    "region_a.download_granules(session,'/Users/jessica/Scripts/github/icesat2py/icepyx/download/', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps required by the user\n",
    "- create icesat2data object with the minimum inputs (dataset, time period, spatial extent)\n",
    "- enter Earthdata login credentials and open an active session\n",
    "- download data (querying can be done prior to logging in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info supplied by the user\n",
    "- dataset of interest, also known as \"short name\".\n",
    "See https://nsidc.org/data/icesat-2/data-sets for a list of the available datasets.\n",
    "- Time period of interest (start date and time, end date and time)\n",
    "- spatial area of interest (now only as a bounding box)\n",
    "\n",
    "- earthdata login and password\n",
    "- valid email address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements to develop further (or include in an example, as in Amy's tutorial)\n",
    "- polygon visualization\n",
    "- input of polygon (including simplification steps) instead of bounding box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info from the user - any subsetting and reformatting requests\n",
    "#### These reformatting options are optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NSIDC DAAC supports customization services on many of our NASA Earthdata mission collections. Reformatting and subsetting are available on all Level-2 and -3 ICESat-2 data sets. Let's discover the specific service options supported for this data set and select which of these services we want to request. \n",
    "\n",
    "We will start by querying the service capability to gather and select customization options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://n5eil02u.ecs.nsidc.org/egi/capabilities/ATL06.002.xml\n"
     ]
    }
   ],
   "source": [
    "# Query service capability URL \n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "short_name = 'ATL06'\n",
    "latest_version = '002'\n",
    "\n",
    "capability_url = f'https://n5eil02u.ecs.nsidc.org/egi/capabilities/{short_name}.{latest_version}.xml'\n",
    "\n",
    "print(capability_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create session to store cookie and pass credentials to capabilities url\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(session.auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = session.get(capability_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = ET.fromstring(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of NSIDC's service endpoints are behind NASA Earthdata Login. We need to create a session to store cookies and pass Earthdata Login credentials to capabilities url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the service capability XML, we can collect lists with each service option to gather service information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-218922eef846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# collect lists with each service option\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msubagent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msubset_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrib\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msubset_agent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SubsetAgent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# variable subsetting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'root' is not defined"
     ]
    }
   ],
   "source": [
    "# collect lists with each service option\n",
    "\n",
    "subagent = [subset_agent.attrib for subset_agent in root.iter('SubsetAgent')]\n",
    "\n",
    "# variable subsetting\n",
    "variables = [SubsetVariable.attrib for SubsetVariable in root.iter('SubsetVariable')]  \n",
    "variables_raw = [variables[i]['value'] for i in range(len(variables))]\n",
    "variables_join = [''.join(('/',v)) if v.startswith('/') == False else v for v in variables_raw] \n",
    "variable_vals = [v.replace(':', '/') for v in variables_join]\n",
    "\n",
    "# reformatting\n",
    "formats = [Format.attrib for Format in root.iter('Format')]\n",
    "format_vals = [formats[i]['value'] for i in range(len(formats))]\n",
    "format_vals.remove('')\n",
    "\n",
    "# reprojection only applicable on ICESat-2 L3B products, yet to be available. \n",
    "\n",
    "# reformatting options that support reprojection\n",
    "normalproj = [Projections.attrib for Projections in root.iter('Projections')]\n",
    "normalproj_vals = []\n",
    "normalproj_vals.append(normalproj[0]['normalProj'])\n",
    "format_proj = normalproj_vals[0].split(',')\n",
    "format_proj.remove('')\n",
    "format_proj.append('No reformatting')\n",
    "\n",
    "#reprojection options\n",
    "projections = [Projection.attrib for Projection in root.iter('Projection')]\n",
    "proj_vals = []\n",
    "for i in range(len(projections)):\n",
    "    if (projections[i]['value']) != 'NO_CHANGE' :\n",
    "        proj_vals.append(projections[i]['value'])\n",
    "        \n",
    "# reformatting options that do not support reprojection\n",
    "no_proj = [i for i in format_vals if i not in format_proj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's confirm that subset services exist for our data set by reviewing the `subagent` list. If the list contains service information, we know that services are available. If not, we need to set the `agent` API parameter to `NO` to indicate that our request will bypass the subsetter. This will quickly send back the data \"natively\" without any customization applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 'ICESAT2', 'spatialSubsetting': 'true', 'spatialSubsettingShapefile': 'true', 'temporalSubsetting': 'true', 'type': 'both', 'maxGransSyncRequest': '100', 'maxGransAsyncRequest': '2000'}]\n"
     ]
    }
   ],
   "source": [
    "print(subagent)\n",
    "if len(subagent) < 1 :\n",
    "    agent = 'NO'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More information is contained in the subagent list, including the maximum number of granules that we can request per order depending on our configuration. We'll come back to these options below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We'll begin populating the subsetting and reformatting parameters used for our NSIDC API request. In addition to the CMR information we queried above, the NSIDC API accepts Key-Value-Pairs (KVPs) for subsetting and reformatting services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start with spatial subsetting. Recall that there are three options to *filter* our search results by spatial constraint: \n",
    "\n",
    "1) Bounding Box: Corresponding to the CMR `bounding_box` KVP\n",
    "\n",
    "2) Polygon coordinate pairs: Corresponding to the CMR `polygon` KVP\n",
    "\n",
    "3) Spatial file input, including Esri Shapefile or KML/KMZ: We simplified the file input to also be read by the CMR `polygon` KVP \n",
    "    \n",
    "#### We see above that `spatialSubsetting` is `true` and `spatialSubsettingShapefile` is `true`. Therefore the same *filtering* options can be applied to our *subset* constraint, with unique KVPs for the subsetting service:\n",
    "\n",
    "1) Bounding Box: `bbox` subset KVP\n",
    "\n",
    "2) Polygon coordinate pairs: `bounding_shape` subset KVP in [GeoJSON](https://geojson.org/) format. \n",
    "\n",
    "3) Spatial file input: The file can be read directly by the subsetter without simplification. This file will be posted to the API endpoint, so we don't need to specify an additional subset KVP here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because we're pursuing option 3), we don't need to provide an additional subset parameter. Below is commented code for bounding box inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporal subsetting is next, since we saw above that `temporalSubsetting` is `true`. We filtered data over 22 Feb 2019 and we can also subset the data to those dates if desired. \n",
    "\n",
    "The `time` KVP is used to subset temporally. This can be entered in the following formats:\n",
    "\n",
    "`time=yyyy-mm-dd,yyyy-mm-dd`\n",
    "\n",
    "`time=yyy-mm-ddThh:MM:ss,yyy-mm-ddThh:MM:ss` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal subsetting KVP\n",
    "\n",
    "timevar = start_date + 'T' + start_time + ',' + end_date + 'T' + end_time\n",
    "print(timevar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's explore the reformatting options available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(format_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These options can be inputted into the API request exactly as printed in the list, with quotes removed, using the `format=` Key-Value-Pair. For example:\n",
    "\n",
    "`format=TABULAR_ASCII`\n",
    "\n",
    "We will be exploring the data in its native HDF5 format so we won't pursue this option in this tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reprojection options will be available on the gridded ICESat-2 L3B data sets. Let's confirm that no reprojection options exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(proj_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, let's determine if variable subsetting is available by finding the length of the `variable_vals` list we gathered from the capabilities URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(variable_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the entire list of variables if desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(variable_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can enter a list of variables to subset separated by comma using the `coverage` key. All forward slashes need to be included to indicate HDF group hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = '/ancillary_data/atlas_sdp_gps_epoch,\\\n",
    "/gt1l/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt1l/land_ice_segments/delta_time,\\\n",
    "/gt1l/land_ice_segments/h_li,\\\n",
    "/gt1l/land_ice_segments/h_li_sigma,\\\n",
    "/gt1l/land_ice_segments/latitude,\\\n",
    "/gt1l/land_ice_segments/longitude,\\\n",
    "/gt1l/land_ice_segments/segment_id,\\\n",
    "/gt1l/land_ice_segments/sigma_geo_h,\\\n",
    "/gt1r/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt1r/land_ice_segments/delta_time,\\\n",
    "/gt1r/land_ice_segments/h_li,\\\n",
    "/gt1r/land_ice_segments/h_li_sigma,\\\n",
    "/gt1r/land_ice_segments/latitude,\\\n",
    "/gt1r/land_ice_segments/longitude,\\\n",
    "/gt1r/land_ice_segments/segment_id,\\\n",
    "/gt1r/land_ice_segments/sigma_geo_h,\\\n",
    "/gt2l/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt2l/land_ice_segments/delta_time,\\\n",
    "/gt2l/land_ice_segments/h_li,\\\n",
    "/gt2l/land_ice_segments/h_li_sigma,\\\n",
    "/gt2l/land_ice_segments/latitude,\\\n",
    "/gt2l/land_ice_segments/longitude,\\\n",
    "/gt2l/land_ice_segments/segment_id,\\\n",
    "/gt2l/land_ice_segments/sigma_geo_h,\\\n",
    "/gt2r/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt2r/land_ice_segments/delta_time,\\\n",
    "/gt2r/land_ice_segments/h_li,\\\n",
    "/gt2r/land_ice_segments/h_li_sigma,\\\n",
    "/gt2r/land_ice_segments/latitude,\\\n",
    "/gt2r/land_ice_segments/longitude,\\\n",
    "/gt2r/land_ice_segments/segment_id,\\\n",
    "/gt2r/land_ice_segments/sigma_geo_h,\\\n",
    "/gt3l/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt3l/land_ice_segments/delta_time,\\\n",
    "/gt3l/land_ice_segments/h_li,\\\n",
    "/gt3l/land_ice_segments/h_li_sigma,\\\n",
    "/gt3l/land_ice_segments/latitude,\\\n",
    "/gt3l/land_ice_segments/longitude,\\\n",
    "/gt3l/land_ice_segments/segment_id,\\\n",
    "/gt3l/land_ice_segments/sigma_geo_h,\\\n",
    "/gt3r/land_ice_segments/atl06_quality_summary,\\\n",
    "/gt3r/land_ice_segments/delta_time,\\\n",
    "/gt3r/land_ice_segments/h_li,\\\n",
    "/gt3r/land_ice_segments/h_li_sigma,\\\n",
    "/gt3r/land_ice_segments/latitude,\\\n",
    "/gt3r/land_ice_segments/longitude,\\\n",
    "/gt3r/land_ice_segments/segment_id,\\\n",
    "/gt3r/land_ice_segments/sigma_geo_h,\\\n",
    "/orbit_info/cycle_number,\\\n",
    "/orbit_info/rgt,\\\n",
    "/orbit_info/orbit_number' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting the request - behind the scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the search query\n",
    "\n",
    "#### We will now populate dictionaries to be applied to our search query below based on spatial and temporal inputs. For additional search parameters, see the [The Common Metadata Repository API documentation](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html \"CMR API documentation\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aoi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ce394993204a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create CMR parameters used for granule search. Modify params depending on bounding_box or polygon input.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0maoi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# bounding box input:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     params = {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aoi' is not defined"
     ]
    }
   ],
   "source": [
    "#Create CMR parameters used for granule search. Modify params depending on bounding_box or polygon input.\n",
    "\n",
    "if aoi == '1':\n",
    "# bounding box input:\n",
    "    params = {\n",
    "    'short_name': short_name,\n",
    "    'version': latest_version,\n",
    "    'temporal': temporal,\n",
    "    'page_size': 100,\n",
    "    'page_num': 1,\n",
    "    'bounding_box': bounding_box\n",
    "    }\n",
    "else:\n",
    "    \n",
    "# If polygon input (either via coordinate pairs or shapefile/KML/KMZ):\n",
    "    params = {\n",
    "    'short_name': short_name,\n",
    "    'version': latest_version,\n",
    "    'temporal': temporal,\n",
    "    'page_size': 100,\n",
    "    'page_num': 1,\n",
    "    'polygon': polygon,\n",
    "    }\n",
    "\n",
    "print('CMR search parameters: ', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input the parameter dictionary to the CMR granule search to query all granules that meet the criteria based on the granule metadata. Print the number of granules returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query number of granules using our (paging over results)\n",
    "\n",
    "granule_search_url = 'https://cmr.earthdata.nasa.gov/search/granules'\n",
    "\n",
    "granules = []\n",
    "while True:\n",
    "    response = requests.get(granule_search_url, params=params, headers=headers)\n",
    "    results = json.loads(response.content)\n",
    "\n",
    "    if len(results['feed']['entry']) == 0:\n",
    "        # Out of results, so break out of loop\n",
    "        break\n",
    "\n",
    "    # Collect results and increment page_num\n",
    "    granules.extend(results['feed']['entry'])\n",
    "    params['page_num'] += 1\n",
    "\n",
    "    \n",
    "# Get number of granules over my area and time of interest\n",
    "len(granules)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granules = region_a.granules\n",
    "len(granules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Although subsetting, reformatting, or reprojecting can alter the size of the granules, this \"native\" granule size can still be used to guide us towards the best download method to pursue, which we will come back to later on in this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request data from the NSIDC data access API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now set up our data download request. The data access and service API (labeled EGI below) incorporates the CMR parameters that we explored above, plus customization service parameters as well as a few configuration parameters.\n",
    "\n",
    "![Data Access Service API diagram](https://gsfc-ngap-developer.s3.amazonaws.com/be03ae4ddbe19c8ea7734df6941385b8baba4741f6c7ec62fd4230eccdc31fc0)\n",
    "\n",
    "#### As described above, the API is structured as a URL with a base plus individual key-value-pairs (KVPs) separated by ‘&’. The base URL of the NSIDC API is: </br>\n",
    "`https://n5eil02u.ecs.nsidc.org/egi/request`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set NSIDC data access base URL\n",
    "base_url = 'https://n5eil02u.ecs.nsidc.org/egi/request'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's go over the configuration parameters:\n",
    "\n",
    "* `request_mode`\n",
    "* `page_size`\n",
    "* `page_num`\n",
    "\n",
    "`request_mode` is \"synchronous\" by default, meaning that the request relies on a direct, continous connection between you and the API endpoint. Outputs are directly downloaded, or \"streamed\" to your working directory. For this tutorial, we will set the request mode to asynchronous, which will allow concurrent requests to be queued and processed without the need for a continuous connection.\n",
    "\n",
    "**Use the streaming `request_mode` with caution: While it can be beneficial to stream outputs directly to your local directory, note that timeout errors can result depending on the size of the request, and your request will not be queued in the system if NSIDC is experiencing high request volume. For best performance, I recommend setting `page_size=1` to download individual outputs, which will eliminate extra time needed to zip outputs and will ensure faster processing times per request. An example streaming request loop is available at the bottom of the tutorial below. **\n",
    "\n",
    "Recall that we queried the total number and volume of granules prior to applying customization services. `page_size` and `page_num` can be used to adjust the number of granules per request up to a limit of 2000 granules for asynchronous, and 100 granules for synchronous (streaming). For now, let's select 10 granules to be processed in each zipped request. For ATL06, the granule size can exceed 100 MB so we want to choose a granule count that provides us with a reasonable zipped download size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of granules requested per order, which we will initially set to 10.\n",
    "page_size = 10\n",
    "\n",
    "#Determine number of pages basd on page_size and total granules. Loop requests by this value\n",
    "page_num = math.ceil(len(granules)/page_size)\n",
    "\n",
    "#Set request mode. \n",
    "request_mode = 'async'\n",
    "\n",
    "# Determine how many individual orders we will request based on the number of granules requested\n",
    "\n",
    "print(page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After all of these KVP inputs, what does our request look like? Here's a summary of all possible KVPs that we explored, both for CMR searching and for the subsetter:\n",
    "\n",
    "#### CMR search keys:\n",
    "* `short_name=`\n",
    "* `version=`\n",
    "* `temporal=`\n",
    "* `bounding_box=`\n",
    "* `polygon=`\n",
    "\n",
    "#### Customization service keys:\n",
    "* `time=`\n",
    "* `bbox=`\n",
    "* `bounding_shape=` \n",
    "* `format=`\n",
    "* `projection=`\n",
    "* `projection_parameters=`\n",
    "* `Coverage=`\n",
    "\n",
    "#### No customization (access only):\n",
    "* `agent=`    \n",
    "* `include_meta=` \n",
    "    * `Y` by default. `N` for No metadata requested.\n",
    "\n",
    "#### Request configuration keys:\n",
    "* `request_mode=` \n",
    "* `page_size=`\n",
    "* `page_num=`\n",
    "* `token=`\n",
    "* `email=`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we were to create an API request based on our request parameters and submit into a web browser for example, here's what we end up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print API base URL + request parameters --> for polygon\n",
    "API_request = f'{base_url}?short_name={short_name}&version={latest_version}&temporal={temporal}&time={timevar}&polygon={polygon}&Coverage={coverage}&request_mode={request_mode}&page_size={page_size}&page_num={page_num}&token={token}&email={email}'\n",
    "print(API_request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print API base URL + request parameters --> for bbox\n",
    "API_request = f'{base_url}?short_name={short_name}&version={latest_version}&temporal={temporal}&time={timevar}\\\n",
    "&bbox={bbox}&Coverage={coverage}&request_mode={request_mode}&page_size={page_size}&page_num={page_num}&token={token}&email={email}'\n",
    "print(API_request)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll also create a new dictionary of NSIDC API KVPs to be used in our subset request. Because we are looping through each page of requests, we'll add the `page_num` KVP to our dictionary within the loop below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_params = {\n",
    "    'short_name': short_name, \n",
    "    'version': latest_version, \n",
    "    'temporal': temporal, \n",
    "    'time': timevar, \n",
    "    'polygon': polygon, \n",
    "    'Coverage': coverage, \n",
    "    'request_mode': request_mode, \n",
    "    'page_size': page_size,  \n",
    "    'token': token, \n",
    "    'email': email, \n",
    "    }\n",
    "print(subset_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_params = {\n",
    "    'short_name': short_name, \n",
    "    'version': latest_version, \n",
    "    'temporal': temporal, \n",
    "    'time': timevar, \n",
    "    'bbox': bbox, \n",
    "    'Coverage': coverage, \n",
    "    'request_mode': request_mode, \n",
    "    'page_size': page_size,  \n",
    "    'token': token, \n",
    "    'email': email, \n",
    "    }\n",
    "print(subset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll request the same data but without any subsetting services applied. Let's create another request parameter dictionary with the `time` and `coverage` service keys removed, and we'll add `agent=NO` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_params = {\n",
    "    'short_name': short_name, \n",
    "    'version': latest_version, \n",
    "    'temporal': temporal, \n",
    "    'bbox': bbox, #'polygon': polygon, \n",
    "    'agent' : 'NO',\n",
    "    'include_meta' : 'Y',\n",
    "    'request_mode': request_mode, \n",
    "    'page_size': page_size,  \n",
    "    'token': token, \n",
    "    'email': email, \n",
    "    }\n",
    "\n",
    "print(request_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Data\n",
    "\n",
    "#### Finally, we'll download the data directly to this notebook directory in a new Outputs folder. The progress of each order will be reported.\n",
    "\n",
    "We'll start by creating an output folder if the folder does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = str(os.getcwd() + '/Outputs')\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll submit our request without subsetting services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data service for each page number, and unzip outputs\n",
    "\n",
    "for i in range(page_num):\n",
    "    page_val = i + 1\n",
    "    print('Order: ', page_val)\n",
    "    request_params.update( {'page_num': page_val} )\n",
    "    \n",
    "# For all requests other than spatial file upload, use get function\n",
    "    request = session.get(base_url, params=request_params)\n",
    "    \n",
    "    print('Request HTTP response: ', request.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    request.raise_for_status()\n",
    "    print('Order request URL: ', request.url)\n",
    "    esir_root = ET.fromstring(request.content)\n",
    "    print('Order request response XML content: ', request.content)\n",
    "\n",
    "#Look up order ID\n",
    "    orderlist = []   \n",
    "    for order in esir_root.findall(\"./order/\"):\n",
    "        orderlist.append(order.text)\n",
    "    orderID = orderlist[0]\n",
    "    print('order ID: ', orderID)\n",
    "\n",
    "#Create status URL\n",
    "    statusURL = base_url + '/' + orderID\n",
    "    print('status URL: ', statusURL)\n",
    "\n",
    "#Find order status\n",
    "    request_response = session.get(statusURL)    \n",
    "    print('HTTP response from order response URL: ', request_response.status_code)\n",
    "    \n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    request_response.raise_for_status()\n",
    "    request_root = ET.fromstring(request_response.content)\n",
    "    statuslist = []\n",
    "    for status in request_root.findall(\"./requestStatus/\"):\n",
    "        statuslist.append(status.text)\n",
    "    status = statuslist[0]\n",
    "    print('Data request ', page_val, ' is submitting...')\n",
    "    print('Initial request status is ', status)\n",
    "\n",
    "#Continue loop while request is still processing\n",
    "    while status == 'pending' or status == 'processing': \n",
    "        print('Status is not complete. Trying again.')\n",
    "        time.sleep(10)\n",
    "        loop_response = session.get(statusURL)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "        loop_response.raise_for_status()\n",
    "        loop_root = ET.fromstring(loop_response.content)\n",
    "\n",
    "#find status\n",
    "        statuslist = []\n",
    "        for status in loop_root.findall(\"./requestStatus/\"):\n",
    "            statuslist.append(status.text)\n",
    "        status = statuslist[0]\n",
    "        print('Retry request status is: ', status)\n",
    "        if status == 'pending' or status == 'processing':\n",
    "            continue\n",
    "\n",
    "#Order can either complete, complete_with_errors, or fail:\n",
    "# Provide complete_with_errors error message:\n",
    "    if status == 'complete_with_errors' or status == 'failed':\n",
    "        messagelist = []\n",
    "        for message in loop_root.findall(\"./processInfo/\"):\n",
    "            messagelist.append(message.text)\n",
    "        print('error messages:')\n",
    "        pprint.pprint(messagelist)\n",
    "\n",
    "# Download zipped order if status is complete or complete_with_errors\n",
    "    if status == 'complete' or status == 'complete_with_errors':\n",
    "        downloadURL = 'https://n5eil02u.ecs.nsidc.org/esir/' + orderID + '.zip'\n",
    "        print('Zip download URL: ', downloadURL)\n",
    "        print('Beginning download of zipped output...')\n",
    "        zip_response = session.get(downloadURL)\n",
    "        # Raise bad request: Loop will stop for bad response code.\n",
    "        zip_response.raise_for_status()\n",
    "        with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "            z.extractall(path)\n",
    "        print('Data request', page_val, 'is complete.')\n",
    "    else: print('Request failed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our request loop again, this time with subsetting services applied. We will post the KML file directly to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request data service for each page number, and unzip outputs\n",
    "\n",
    "for i in range(page_num):\n",
    "    page_val = i + 1\n",
    "    print('Order: ', page_val)\n",
    "    subset_params.update( {'page_num': page_val} )\n",
    "    \n",
    "# Post polygon to API endpoint for polygon subsetting to subset based on original, non-simplified KML file\n",
    "\n",
    "#     shape_post = {'shapefile': open(kml_filepath, 'rb')}\n",
    "#     request = session.post(base_url, params=subset_params, files=shape_post) \n",
    "    \n",
    "# FOR ALL OTHER REQUESTS THAT DO NOT UTILIZED AN UPLOADED POLYGON FILE, USE A GET REQUEST INSTEAD OF POST:\n",
    "    request = session.get(base_url, params=request_params)\n",
    "    \n",
    "    print('Request HTTP response: ', request.status_code)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    request.raise_for_status()\n",
    "    print('Order request URL: ', request.url)\n",
    "    esir_root = ET.fromstring(request.content)\n",
    "    print('Order request response XML content: ', request.content)\n",
    "\n",
    "# Look up order ID\n",
    "    orderlist = []   \n",
    "    for order in esir_root.findall(\"./order/\"):\n",
    "        orderlist.append(order.text)\n",
    "    orderID = orderlist[0]\n",
    "    print('order ID: ', orderID)\n",
    "\n",
    "# Create status URL\n",
    "    statusURL = base_url + '/' + orderID\n",
    "    print('status URL: ', statusURL)\n",
    "\n",
    "# Find order status\n",
    "    request_response = session.get(statusURL)    \n",
    "    print('HTTP response from order response URL: ', request_response.status_code)\n",
    "    \n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "    request_response.raise_for_status()\n",
    "    request_root = ET.fromstring(request_response.content)\n",
    "    statuslist = []\n",
    "    for status in request_root.findall(\"./requestStatus/\"):\n",
    "        statuslist.append(status.text)\n",
    "    status = statuslist[0]\n",
    "    print('Data request ', page_val, ' is submitting...')\n",
    "    print('Initial request status is ', status)\n",
    "\n",
    "# Continue to loop while request is still processing\n",
    "    while status == 'pending' or status == 'processing': \n",
    "        print('Status is not complete. Trying again.')\n",
    "        time.sleep(10)\n",
    "        loop_response = session.get(statusURL)\n",
    "\n",
    "# Raise bad request: Loop will stop for bad response code.\n",
    "        loop_response.raise_for_status()\n",
    "        loop_root = ET.fromstring(loop_response.content)\n",
    "\n",
    "# Find status\n",
    "        statuslist = []\n",
    "        for status in loop_root.findall(\"./requestStatus/\"):\n",
    "            statuslist.append(status.text)\n",
    "        status = statuslist[0]\n",
    "        print('Retry request status is: ', status)\n",
    "        if status == 'pending' or status == 'processing':\n",
    "            continue\n",
    "\n",
    "# Order can either complete, complete_with_errors, or fail:\n",
    "# Provide complete_with_errors error message:\n",
    "    if status == 'complete_with_errors' or status == 'failed':\n",
    "        messagelist = []\n",
    "        for message in loop_root.findall(\"./processInfo/\"):\n",
    "            messagelist.append(message.text)\n",
    "        print('error messages:')\n",
    "        pprint.pprint(messagelist)\n",
    "\n",
    "# Download zipped order if status is complete or complete_with_errors\n",
    "    if status == 'complete' or status == 'complete_with_errors':\n",
    "        downloadURL = 'https://n5eil02u.ecs.nsidc.org/esir/' + orderID + '.zip'\n",
    "        print('Zip download URL: ', downloadURL)\n",
    "        print('Beginning download of zipped output...')\n",
    "        zip_response = session.get(downloadURL)\n",
    "        # Raise bad request: Loop will stop for bad response code.\n",
    "        zip_response.raise_for_status()\n",
    "        with zipfile.ZipFile(io.BytesIO(zip_response.content)) as z:\n",
    "            z.extractall(path)\n",
    "        print('Data request', page_val, 'is complete.')\n",
    "    else: print('Request failed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why did we get an error? \n",
    "\n",
    "Errors can occur when our search filter overestimates the extent of the data contained within the granule. CMR uses orbit metadata to determine the extent of the file, including the following parameters:\n",
    "\n",
    "Collection-level:\n",
    "* `SwathWidth`\n",
    "* `Period`\n",
    "* `InclinationAngle`\n",
    "* `NumberOfOrbits` \n",
    "* `StartCircularLatitude` \n",
    "\n",
    "Granule level: \n",
    "* `AscendingCrossing`\n",
    "* `StartLatitude`\n",
    "* `StartDirection`\n",
    "* `EndLatitude`\n",
    "* `EndDirection` \n",
    "\n",
    "However, the values themselves are not inspected during our search. This can be a relatively common error for ICESat-2 search and access because of the limitations of the metadata, but it only means that more data were returned in the search results as a \"false positive\" compared to what the subsetter found when cropping the data values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean up the Output folder by removing individual order folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean up Outputs folder by removing individual granule folders \n",
    "\n",
    "for root, dirs, files in os.walk(path, topdown=False):\n",
    "    for file in files:\n",
    "        try:\n",
    "            shutil.move(os.path.join(root, file), path)\n",
    "        except OSError:\n",
    "            pass\n",
    "        \n",
    "for root, dirs, files in os.walk(path):\n",
    "    for name in dirs:\n",
    "        os.rmdir(os.path.join(root, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List files\n",
    "sorted(os.listdir(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're interested in the streaming request method, an example loop is below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set page size to 1 to improve performance\n",
    "page_size = 1\n",
    "request_params.update( {'page_size': page_size})\n",
    "\n",
    "# No metadata to only return a single output\n",
    "request_params.update( {'include_meta': 'N'})\n",
    "\n",
    "#Determine number of pages basd on page_size and total granules. Loop requests by this value\n",
    "page_num = math.ceil(len(granules)/page_size)\n",
    "print(page_num)\n",
    "\n",
    "#Set request mode. \n",
    "request_params.update( {'request_mode': 'stream'})\n",
    "\n",
    "print(request_params)\n",
    "\n",
    "os.chdir(path)\n",
    "\n",
    "for i in range(page_num):\n",
    "    page_val = i + 1\n",
    "    print('Order: ', page_val)\n",
    "    request_params.update( {'page_num': page_val})\n",
    "    request = session.get(base_url, params=request_params)\n",
    "    print('HTTP response from order response URL: ', request.status_code)\n",
    "    request.raise_for_status()\n",
    "    d = request.headers['content-disposition']\n",
    "    fname = re.findall('filename=(.+)', d)\n",
    "    open(eval(fname[0]), 'wb').write(request.content)\n",
    "    print('Data request', page_val, 'is complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we request the data and download the outputs, let's explore some simple comparisons of the data from s3 that we've already requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for output folders\n",
    "\n",
    "opath = '/home/jovyan/data-access/data-access-outputs'\n",
    "sopath = '/home/jovyan/data-access/data-access-subsetted-outputs'\n",
    "\n",
    "# Choose the same native/subsetted file to compare\n",
    "\n",
    "native_file = opath + '/ATL06_20190222031203_08500210_001_01.h5'\n",
    "processed_file = sopath + '/processed_ATL06_20190222031203_08500210_001_01.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare file sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(native_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.getsize(processed_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files using h5py and compare the HDF5 groups and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files using h5py package\n",
    "\n",
    "native = h5py.File(native_file, 'r')\n",
    "processed = h5py.File(processed_file, 'r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Native file groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGroups = True\n",
    "groups = list(native.keys())\n",
    "for g in groups:\n",
    "    group = native[g]\n",
    "    if printGroups:\n",
    "        print('---')\n",
    "        print('Group: {}'.format(g))\n",
    "        print('---')\n",
    "        for d in group.keys():\n",
    "            print(group[d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetted file groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGroups = True\n",
    "groups = list(processed.keys())\n",
    "for g in groups:\n",
    "    group = processed[g]\n",
    "    if printGroups:\n",
    "        print('---')\n",
    "        print('Group: {}'.format(g))\n",
    "        print('---')\n",
    "        for d in group.keys():\n",
    "            print(group[d])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare geolocation range from the /gt1l/land_ice_segments group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(native_file,'r') as native:\n",
    "    native_groups = list(native.keys())\n",
    "    n_hvar = native['/gt1l/land_ice_segments/h_li']\n",
    "    n_h = n_hvar[:]\n",
    "    n_latvar = native['/gt1l/land_ice_segments/latitude']\n",
    "    n_latitude = n_latvar[:]\n",
    "    n_lonvar = native['/gt1l/land_ice_segments/longitude']\n",
    "    n_longitude = n_lonvar[:]\n",
    "\n",
    "with h5py.File(processed_file,'r') as processed:\n",
    "    processed_groups = list(processed.keys())\n",
    "    p_hvar = processed['/gt1l/land_ice_segments/h_li']\n",
    "    p_h = p_hvar[:]\n",
    "    p_latvar = processed['/gt1l/land_ice_segments/latitude']\n",
    "    p_latitude = p_latvar[:]\n",
    "    p_lonvar = processed['/gt1l/land_ice_segments/longitude']\n",
    "    p_longitude = p_lonvar[:]\n",
    "    \n",
    "print('array size of native file height variable:')\n",
    "print(len(n_h))\n",
    "print('array size of subsetted height variable:')\n",
    "print(len(p_h))\n",
    "\n",
    "print('native file latitude range:')\n",
    "print(min(n_latitude), max(n_latitude))\n",
    "print('native file longitude range:')\n",
    "print(min(n_longitude), max(n_longitude))\n",
    "\n",
    "print('subsetted file latitude range:')\n",
    "print(min(p_latitude), max(p_latitude))\n",
    "print('subsetted file longitude range:')\n",
    "print(min(p_longitude), max(p_longitude))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
