{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c71ca5",
   "metadata": {},
   "source": [
    "# Reproducible investigations of maritime glaciers using open-source tools\n",
    "This notebook ({nb-download}`download <IS2_OSS-FAIR-Resources_Workflow.ipynb>`) illustrates the use of multiple open-source tools (icepyx, IceFlow, SlideRule) for exploring an Alaskan maritime glacier.\n",
    "\n",
    "The notebook was designed for a presentation at the June 2022 International Glaciological Society (IGS) [International Symposium on Maritime Glaciers](https://www.igsoc.org/event/international-symposium-on-maritime-glaciers) in Juneau, Alaska, USA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9b13a4",
   "metadata": {},
   "source": [
    "**Symposium Abstract:**\n",
    "Multiple open-source software (OSS) packages developed by and for the glaciological community enable rapid investigations of maritime glaciers. Focusing on Alaskan maritime glaciers, we illustrate how icepyx and other community-built software packages can be leveraged to quickly explore ICESat-2 data in combination with data from other sensors for a given glacier. The first tool showcased, the Python package icepyx, was created by the author in response to challenges faced by the glaciology community in accessing ICESat-2 data programmatically. With icepyx, we query and quickly visualize ICESat-2 data of the glacier. Then, we construct a time series of elevations spanning the ICESat, IceBridge, and ICESat-2 sensors using the NSIDC IceFlow package. Last, we customize our ICESat-2 data analyses with in-cloud processing using SlideRule. The workflow, encapsulated within an executable Jupyter Notebook, showcases the tools' ease of use for data access, analysis, and visualization while demonstrating the application of FAIR (Findable, Accessible, Interoperable, Reusable) principles and collaborative development in glaciological research.\n",
    "\n",
    "\n",
    "### Tools Showcased\n",
    " 1. [icepyx]()\n",
    " 2. [IceFlow]()\n",
    " 3. [SlideRule]()\n",
    "\n",
    "\n",
    "### Objectives\n",
    " 1. Showcase several open-source tools useful to glaciologists\n",
    " 2. Demonstrate the application of FAIR principles in glaciological research\n",
    " 3. Investigate a maritime glacier..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e01051",
   "metadata": {},
   "source": [
    "# TO DO:\n",
    "- add links to tools\n",
    "- update science and FAIR objectives\n",
    "- add refs/source material\n",
    "- figures/images (use table Mikala made)\n",
    "- clean up!\n",
    "- open issues as needed/track changes to code base\n",
    "\n",
    "## Maybe to-do:\n",
    "- get RGI from NSIDC via CMR, if it's an option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bbaeea",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30fa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "import geopandas as gpd\n",
    "%load_ext autoreload\n",
    "import icepyx as ipx\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d5673a",
   "metadata": {},
   "source": [
    "### Regional Extent\n",
    "\n",
    "The Randolph Glacier Inventory ([RGI](https://nsidc.org/data/nsidc-0770)), part of Global Land Ice Measurements from Space ([GLIMS](https://www.glims.org/))b provides glacier outlines. Here we'll open the Alaska glacier outlines into a GeoPandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba412ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RGI glacier polygons\n",
    "rgi_zip_fn = '01_rgi60_Alaska.zip'\n",
    "url = 'https://www.glims.org/RGI/rgi60_files/' + rgi_zip_fn\n",
    "ak_rgi_gdf = gpd.read_file(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7927a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_rgi_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616fabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak_rgi_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ce42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a glacier\n",
    "# ak_rgi_gdf[~ak_rgi_gdf[\"Name\"].isnull()]\n",
    "glac = ak_rgi_gdf[ak_rgi_gdf[\"Name\"] == \"Mendenhall Glacier\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b56d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glac.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b680450",
   "metadata": {},
   "source": [
    "### ICESat-2 data via icepyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125ff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get exterior coordinates of the glacier polygon\n",
    "poly = list(glac.geometry.values[0].exterior.coords)\n",
    "\n",
    "# simplify polygon for CMR\n",
    "simp_poly = list(glac.simplify(0.01).geometry.values[0].exterior.coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec93c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "simp_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b43e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an icepyx Query object\n",
    "is2_glac = ipx.Query(spatial_extent=simp_poly, \n",
    "                     date_range=['2021-06-01','2021-07-01'], \n",
    "                     product=\"ATL06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b54e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "is2_glac.avail_granules(ids=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11244658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize our outline on a map\n",
    "is2_glac.visualize_spatial_extent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4e4188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick-view available ICESat-2 data with icepyx\n",
    "cyclemap, rgtmap = is2_glac.visualize_elevation()\n",
    "cyclemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cef73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgtmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c16218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# download the data with icepyx\n",
    "path = \"./is2-download\"\n",
    "\n",
    "is2_glac.earthdata_login(uid='icepyx_devteam', email='icepyx.dev@gmail.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d39dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "is2_glac.download_granules(path=path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372c6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some basic data read in and analysis!\n",
    "pattern = \"processed_ATL{product:2}_{datetime:%Y%m%d%H%M%S}_{rgt:4}{cycle:2}{orbitsegment:2}_{version:3}_{revision:2}.h5\"\n",
    "reader = ipx.Read(path, \"ATL06\", pattern) # or ipx.Read(filepath, \"ATLXX\") if your filenames match the default pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c672531",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader._filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e771c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd93278",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5pt = h5py.File(reader._filelist[1],'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558c9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    list(h5pt['gt1r'].keys()),\n",
    "    list(h5pt['gt1l'].keys()),\n",
    "    list(h5pt['gt2r'].keys()),\n",
    "    list(h5pt['gt2l'].keys()),\n",
    "    list(h5pt['gt3r'].keys()),\n",
    "    list(h5pt['gt3l'].keys()),\n",
    ")\n",
    "\n",
    "# New Issue (see line 599 of read module)\n",
    "### Why are gt1r and gt1l being returned (e.g. residual histogram) being included in subset file from NSIDC if there's no geospatial data there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21818d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get desired variables\n",
    "reader.vars.append(var_list=['h_li', \"latitude\", \"longitude\"])\n",
    "reader.vars.wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a86b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "is2_ds = reader.load()\n",
    "is2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "is2_merge = xr.merge(is2_ds, compat='override')\n",
    "is2_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick preview!\n",
    "is2_merge.plot.scatter(x=\"longitude\", y=\"latitude\", hue=\"h_li\", vmin=-100, vmax=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edebdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a better map/plot here so can see where the points fall!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f9738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44d2f59f",
   "metadata": {},
   "source": [
    "-------------\n",
    "## IceFlow\n",
    "\n",
    "Use IceFlow to get a longer time-series of data from ICESat, IceBridge, and ICESat-2.\n",
    "\n",
    "For more details on the inputs selected here, see [this time series tutorial notebook](https://github.com/nsidc/NSIDC-Data-Tutorials/blob/main/notebooks/iceflow/4_time_series_tutorial.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f2cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add packages to environment (if you didn't when creating your environment)\n",
    "!pip install ipyleaflet ipympl python-cmr sidecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790142b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add location of iceflow module to path and import \n",
    "# (note this is system-dependent and requires that you first clone the library from GitHub)\n",
    "import importlib\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/jessica/computing/misc/github/NSIDC-Data-Tutorials/notebooks/iceflow/\")\n",
    "iceflow = importlib.__import__(\"iceflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f63f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Earthdata authentication (someday this will hopefully be streamlined with icepyx so you only need to log in once!)\n",
    "client = iceflow.ui.IceFlowUI()\n",
    "client.display_credentials()\n",
    "\n",
    "authorized = client.authenticate()\n",
    "if authorized is None:\n",
    "    print('Earthdata Login not successful')\n",
    "else:\n",
    "    print('Earthdata Login successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d510507",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_box_poly = list(is2_glac._spat_extent.envelope.exterior.coords)\n",
    "bound_box_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ca083",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_box = ','.join([str(bound_box_poly[0][0]), str(bound_box_poly[0][1]), \n",
    "                      str(bound_box_poly[2][0]), str(bound_box_poly[2][1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6345b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameters needed for ordering data via IceFlow\n",
    "ifl_params ={\n",
    "    'datasets': ['GLAH06', 'ATM1B', 'ILVIS2'],\n",
    "    'start': '1993-01-01',\n",
    "    'end': '2018-12-31',\n",
    "    'bbox': bound_box,\n",
    "    # Here we will select ITRF2014 to match the Epoch of the most recent ICESat-2 granule we are ordering\n",
    "    'itrf': 'ITRF2014',\n",
    "    'epoch': '2018.12'\n",
    "}\n",
    "\n",
    "# returns a json dictionary, the request parameters, and the order's response.\n",
    "granules_metadata = client.query_cmr(params=ifl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25464ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update input parameters so an order is not placed for datasets with no granules\n",
    "ifl_params['datasets'] = ['GLAH06']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# place order\n",
    "ifl_order = client.place_data_orders(params=ifl_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873eab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check order status\n",
    "for order in ifl_order:\n",
    "    status = client.order_status(order)\n",
    "    print(order['dataset'], order['id'], status['status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb31b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data (once all orders are COMPLETE)\n",
    "for order in ifl_order:\n",
    "    status = client.order_status(order)\n",
    "    if status['status'] == 'COMPLETE':\n",
    "        client.download_order(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook is running outside the IceFlow module\n",
    "!pwd\n",
    "\n",
    "# get the path where IceFlow data was automatically downloaded\n",
    "ifl_path = Path(iceflow.__file__).parent.joinpath('../data')\n",
    "print('\\n', ifl_path)\n",
    "\n",
    "# get the list of downloaded files\n",
    "ifl_filelist = [p for p in ifl_path.iterdir() if (p.is_file() and p.glob(\"*-2022*.h5\"))]\n",
    "print('\\n', ifl_filelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifl_filelist[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e9fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "\n",
    "# ICESat granule data\n",
    "glas_gdf = iceflow.processing.IceFlowProcessing.to_geopandas(ifl_filelist[4]) # UPDATE PATH BASED ON YOUR OUTPUTTED FILENAME\n",
    "glas_gdf['mission'] = \"IS\"\n",
    "glas_gdf['time'] = pd.to_datetime(glas_gdf.index.astype(str))\n",
    "\n",
    "# #Pre-IceBridge/IceBridge ATM granule data\n",
    "# preib_gdf = ifp.to_geopandas('data/ATM1B-20210423-Sample.h5') # UPDATE PATH BASED ON YOUR OUTPUTTED FILENAME\n",
    "# preib_gdf['mission'] = \"IB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "glas_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f7ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "is2_merge # instead, consider turning it into a dataframe for plotting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf800e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs #geospatial (mapping) plotting library\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt #Python visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de7b875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that although this data is projected, it is not recommended you use this map as a basis for geospatial analysis\n",
    "\n",
    "# Create a Stamen terrain background instance.\n",
    "stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "\n",
    "map_fig = plt.figure()\n",
    "# Create a GeoAxes in the tile's projection.\n",
    "map_ax = map_fig.add_subplot(111, projection=stamen_terrain.crs)\n",
    "\n",
    "# Limit the extent of the map to a small longitude/latitude range.\n",
    "map_ax.set_extent([-135, -134, 58.1, 58.9], crs=ccrs.Geodetic())\n",
    "\n",
    "# Add the Stamen data at zoom level 8.\n",
    "map_ax.add_image(stamen_terrain, 8)\n",
    "\n",
    "for onegdf, lab, shp in zip([glas_gdf],[\"is\"], ['o']):\n",
    "    ms=map_ax.scatter(onegdf[\"longitude\"], onegdf[\"latitude\"],  2, c=onegdf[\"elevation\"],\n",
    "                      vmin=0, vmax=1000, label=lab, marker=shp,\n",
    "                      transform=ccrs.Geodetic())\n",
    "\n",
    "for oneds, lab, shp in zip([is2_merge],[\"IS2\"], ['D']):\n",
    "    ms=map_ax.scatter(oneds[\"longitude\"], oneds[\"latitude\"],  2, c=oneds[\"h_li\"],\n",
    "                      vmin=0, vmax=1000, label=lab, marker=shp,\n",
    "                      transform=ccrs.Geodetic())\n",
    "plt.colorbar(ms, label='elevation');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d5e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c609924d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at a time series or something (as in NSIDC example)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d702844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f4c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get higher-resolution ICESat-2 data with SlideRule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4c124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b36f20bc",
   "metadata": {},
   "source": [
    "**Credits**\n",
    "* notebook by: Jessica Scheick\n",
    "* notebook contributors: \n",
    "* source material: []() by ???"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
